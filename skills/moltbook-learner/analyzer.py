#!/usr/bin/env python3
"""
Moltbook å­¦ä¹ è€… - åˆ†æè„šæœ¬
åˆ†æå¸–å­å†…å®¹ï¼Œæå–å…³é”®çŸ¥è¯†ï¼Œè¯„ä¼°ä»·å€¼
"""

import json
import os
from datetime import datetime

# é…ç½®
DATA_DIR = os.path.join(os.path.dirname(__file__), "data")
POSTS_DIR = os.path.join(DATA_DIR, "posts")
ANALYZED_DIR = os.path.join(DATA_DIR, "analyzed")
LEARNED_DIR = os.path.join(DATA_DIR, "learned")

def load_latest_posts():
    """åŠ è½½æœ€æ–°çš„å¸–å­æ–‡ä»¶"""
    files = sorted([f for f in os.listdir(POSTS_DIR) if f.endswith(".json")])
    if not files:
        return None
    
    latest = os.path.join(POSTS_DIR, files[-1])
    with open(latest, encoding="utf-8") as f:
        return json.load(f)

def analyze_post(post):
    """åˆ†æå•ä¸ªå¸–å­"""
    title = post.get("title", "")
    content = post.get("content", "")
    author = post.get("author", {}).get("name", "Unknown")
    upvotes = post.get("upvotes", 0)
    
    # æå–å…³é”®è¯
    keywords = []
    tech_keywords = ["API", "skill", "tool", "function", "method", "system"]
    for kw in tech_keywords:
        if kw.lower() in content.lower():
            keywords.append(kw)
    
    # è¯„ä¼°ä»·å€¼
    novelty = 3  # åŸºç¡€åˆ†
    if "new" in content.lower() or "first" in content.lower():
        novelty = 4
    if "original" in content.lower() or "innovate" in content.lower():
        novelty = 5
    
    feasibility = 3  # åŸºç¡€åˆ†
    if "code" in content.lower() or "example" in content.lower():
        feasibility = 4
    if "implement" in content.lower() or "step" in content.lower():
        feasibility = 5
    
    practicality = 3  # åŸºç¡€åˆ†
    if upvotes > 100:
        practicality = 4
    if upvotes > 1000:
        practicality = 5
    
    # æ€»åˆ†
    total_score = (novelty + feasibility + practicality) / 3
    
    # åˆ†ç±»
    category = "general"
    if "skill" in content.lower() or "tool" in content.lower():
        category = "skill"
    elif "learning" in content.lower() or "evolution" in content.lower():
        category = "learning"
    elif "security" in content.lower() or "audit" in content.lower():
        category = "security"
    elif "tutorial" in content.lower() or "guide" in content.lower():
        category = "tutorial"
    
    return {
        "title": title,
        "content": content[:500],  # ä¿ç•™å‰500å­—ç¬¦
        "author": author,
        "upvotes": upvotes,
        "category": category,
        "keywords": keywords,
        "scores": {
            "novelty": novelty,
            "feasibility": feasibility,
            "practicality": practicality,
            "total": round(total_score, 2)
        },
        "analyzed_at": datetime.now().isoformat()
    }

def internalize(analyzed):
    """å°†åˆ†æç»“æœå†…åŒ–ä¸ºå¯æ‰§è¡Œçš„çŸ¥è¯†"""
    learned = []
    
    for post in analyzed:
        if post["scores"]["total"] >= 4.0:  # é«˜ä»·å€¼å†…å®¹
            entry = {
                "title": post["title"],
                "author": post["author"],
                "category": post["category"],
                "key_points": extract_key_points(post["content"]),
                "score": post["scores"]["total"],
                "learned_at": datetime.now().isoformat()
            }
            learned.append(entry)
    
    return learned

def extract_key_points(content):
    """æå–å…³é”®è¦ç‚¹"""
    # ç®€å•æå–ï¼šä»¥å¥å·åˆ†éš”çš„å¥å­
    sentences = content.split("ã€‚")
    points = [s.strip() for s in sentences if len(s.strip()) > 20][:5]
    return points

def save_analysis(analyzed):
    """ä¿å­˜åˆ†æç»“æœ"""
    filename = f"analyzed_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    filepath = os.path.join(ANALYZED_DIR, filename)
    
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(analyzed, f, ensure_ascii=False, indent=2)
    
    print(f"âœ“ Saved analysis to {filename}")
    return filepath

def save_learned(learned):
    """ä¿å­˜å·²å†…åŒ–çš„çŸ¥è¯†"""
    if not learned:
        print("âš ï¸ No high-value content to internalize")
        return
    
    filename = f"learned_{datetime.now().strftime('%Y%m%d')}.md"
    filepath = os.path.join(LEARNED_DIR, filename)
    
    # è½¬æ¢ä¸º Markdown
    md = f"# ğŸ¤– Moltbook æ¯æ—¥å­¦ä¹ \n\n"
    md += f"**æ—¥æœŸ**: {datetime.now().strftime('%Y-%m-%d')}\n\n"
    md += f"**å­¦ä¹ æ¡ç›®**: {len(learned)}\n\n"
    md += "---\n\n"
    
    for i, item in enumerate(learned, 1):
        md += f"## {i}. {item['title']}\n\n"
        md += f"- **ä½œè€…**: {item['author']}\n"
        md += f"- **åˆ†ç±»**: {item['category']}\n"
        md += f"- **è¯„åˆ†**: â­{item['score']}\n"
        md += f"- **è¦ç‚¹**:\n"
        for point in item['key_points']:
            md += f"  - {point}\n"
        md += "\n---\n\n"
    
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(md)
    
    print(f"âœ“ Saved learned knowledge to {filename}")
    return filepath

def main():
    print("ğŸ§  Moltbook Learner - Starting analysis...")
    
    # åŠ è½½å¸–å­
    data = load_latest_posts()
    if not data:
        print("âš ï¸ No posts found. Run fetcher.py first!")
        return
    
    posts = data.get("posts", [])
    print(f"ğŸ“¥ Analyzing {len(posts)} posts...")
    
    # åˆ†æ
    analyzed = [analyze_post(p) for p in posts]
    analyzed.sort(key=lambda x: x["scores"]["total"], reverse=True)
    
    # ä¿å­˜åˆ†æ
    save_analysis(analyzed)
    
    # å†…åŒ–
    learned = internalize(analyzed)
    save_learned(learned)
    
    # æ‰“å°æ‘˜è¦
    print(f"\nğŸ“Š Analysis Summary:")
    print(f"  - Total posts: {len(analyzed)}")
    print(f"  - High-value (â­4+): {len(learned)}")
    
    if learned:
        print(f"\nğŸŒŸ Top learnings:")
        for i, item in enumerate(learned[:3], 1):
            print(f"  {i}. {item['title'][:50]}... (â­{item['score']})")
    
    print("\nâœ… Analysis complete!")

if __name__ == "__main__":
    main()
